/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    waterisk Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

manifest {
    name            = 'WATERISK'
    author          = """Vahiniaina ANDRIAMANGA"""
    homePage        = 'https://github.com/NjivaAndriamanga/waterisk'
    description     = """Assemble bacterial genome from long read sequencing to detect AMR and MGE association"""
    mainScript      = 'main.nf'
    nextflowVersion = '!>=23.04.3'
    version         = '1.0dev'
    doi             = ''
}

params {

    //Mandatory options
    output_dir = "resmobilys_output/" //output directory
    index_file = null //path/to/index_file

    //Quality control
    trim_end_size = 0
    quality_trim = 0
    lineage_db = "bacteria_odb10"

    //Hybracter parameters
    read_min_length = 1000
    medaka = true
    flyeModel = null

    //Tools parameters
    plasmid = "plasme"
    plasme_db = "${projectDir}/DB"
    platon_db = "${projectDir}/platon_db"
    kraken_index = "https://genome-idx.s3.amazonaws.com/kraken/k2_standard_08gb_20240904.tar.gz"
    kraken_db = "${projectDir}/kraken_DB"
    kraken_taxonomy = false
    vf_db = "${projectDir}/VF_db/VFDB_setB_nt.fas"
    rgi_include_nudge = true
    ice_avg_size = 80000
    compositeIS_size = 20000

    //Blast parameter for VF and ICE
    evalue_vf = 1e-03
    pident_vf = 80
    
    //max ressource options. Expecting to be overwritten
    //default: expected to run on local computer with 20 cpus and 32 GB of ram. Expecting to be overwritten
    default_cpus = 4
    default_memory = 8.GB

    //max: expected to run on hpc. Expecting to be overwritten depending the profile
    max_cpus = 16
    max_memory = 32.GB

    //Boilerplate options
    publish_dir_mode = 'symlink'
    email_on_fail = null
    plaintext_email = false

    //Schema validation default option
    validate_params = true

}

profiles {
    
    slurm {
        process {
            scratch = true
            cache = true
            executor = "slurm"
            queue = "workq"
            queueSize = 20
            cpus = params.default_cpus
            memory = params.default_memory
        }
    }

    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }

    docker {
        conda.enabled          = false
        docker.enable          = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
        singularity.cacheDir = "${projectDir}/containers"
        singularity.runOptions = "--bind $HOME"
        singularity.pullTimeout = "1h"
    }

    singularity {
        conda.enabled          = false
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        singularity.enabled    = true
        singularity.autoMounts = true
        singularity.cacheDir = "${projectDir}/containers"
        singularity.runOptions = "--bind $HOME"
        singularity.pullTimeout = "1h"
    }

    podman {
        podman.enabled         = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    
    shifter {
        shifter.enabled        = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    
    charliecloud {
        charliecloud.enabled   = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        apptainer.enabled      = false
    }

    apptainer {
        apptainer.enabled      = true
        apptainer.autoMounts   = true
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.cacheDir = "${projectDir}/containers"
        apptainer.runOptions = "--bind ${HOME}/.cache"
        apptainer.pullTimeout = "1h"
    }

    gitpod {
        executor.name          = 'local'
        executor.cpus          = 16
        executor.memory        = 60.GB
    }

    arm {
        docker.runOptions = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }

    local {

        process {
            scratch = false
            executor = 'local'
            withLabel: 'process_high' { //If you are running localy, change max_cpus and max_memory
                cpus = params.max_cpus
                memory = params.max_memory
            }
        }
    }

    test {
        scratch = false
        executor = 'local'
        includeConfig "${projectDir}/conf/test.config"
        withLabel: 'process_medium' { 
                cpus = params.default_cpus
                memory = params.default_memory
        }
        withLabel: 'process_high' {
            cpus = params.max_cpus
            memory = params.max_memory
        }
    }
}


// Set default registry for Apptainer, Docker, Podman and Singularity independent of -profile
// Will not be used unless Apptainer / Docker / Podman / Singularity are enabled
// Set to your registry if you have a mirror of containers
apptainer.registry   = 'quay.io'
docker.registry      = 'quay.io'
podman.registry      = 'quay.io'
singularity.registry = 'quay.io'

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/base.config'
includeConfig 'conf/module.config'

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.output_dir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.output_dir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.output_dir}/pipeline_info/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.output_dir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}

// Nextflow plugins
plugins {
     id 'nf-schema@2.2.0' // Validation of pipeline parameters and creation of an input channel from a sample sheet
}

validation {
    help {
        enabled = true
        command = "nextflow run waterisk -profile local/slurm,singularity/apptainer/docker -c resmobilys/personnal.config"
    }
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
